# -Build-RAG-AI-Agents-Chatbots-MCP-
Building real-world application like RAG systems, Chatbots, AI agents, MCP servers, LangChain, LlamaIndex, CrewAI, Docker, and AWS EC2.

1. Generative AI – Foundation – Understand AI vs ML vs DL vs GenAI, dive into Large Language Models, and learn the Transformer architecture.

2. Accessing LLMs in Python – Use OpenAI, Gemini, Groq, and Ollama LLMs, and connect them through LangChain and LlamaIndex.

3. Prompt Engineering – Explore prompt templates, zero-shot, and few-shot prompting to effectively interact with LLMs.

4. Building GenAI Chatbots – Build and deploy chatbots step by step using LangChain, LlamaIndex, Streamlit UI, and Streamlit Cloud.

5. Retrieval-Augmented Generation (RAG) – Understand RAG, build RAG pipelines with LangChain and LlamaIndex, and create a PDF Q&A bot.

6. AI Agents – Learn what AI agents are and build agents with PydanticAI, AutoGen, and CrewAI for multi-agent workflows.

7. LLM Deployment – Deploy open-source LLMs with Ollama, Docker, and vLLM, and set them up on AWS EC2 for real-world usage.

8. Model Context Protocol (MCP) – Understand MCP, build an MCP server, and integrate MCP tools with PydanticAI and CrewAI agents.

9. Deploy LLM-powered solutions on the cloud using Docker, Streamlit, Ollama, vLLM, and AWS EC2.
